{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_dataset\n",
    "from load_data import load_glove_model\n",
    "import pos_emoticon_lr as pe_lr\n",
    "import pos_emo_w2v_lr as pew_lr\n",
    "import train\n",
    "from sklearn.metrics import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dataset...\n",
      "removing urls from tweets...\n",
      "Done.  3817  tweets loaded!\n",
      "\n",
      "Loading Glove Model...\n",
      "Done.  400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "root = \"/Users/shikha/UMass/fall2017/NLP/projects\"\n",
    "dataset = root + \"/irony/SemEval2018-Task3/datasets\"\n",
    "glove_file = root + \"/glove.6B/glove.6B.100d.txt\"\n",
    "\n",
    "# Load dataset\n",
    "filename = dataset + \"/train/abc\"\n",
    "X, Y = load_dataset(filename)\n",
    "train_len = int(0.8 * X.shape[0])\n",
    "X_train = X[0:train_len]\n",
    "Y_train = Y[0:train_len]\n",
    "X_test = X[train_len:]\n",
    "Y_test = Y[train_len:]\n",
    "\n",
    "# Load glove file\n",
    "w2v = load_glove_model(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the classifier\n",
    "classifier = pe_lr.initialize_classifier()\n",
    "# classifier = pew_lr.initialize_classifier(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets classified: 3817\n",
      "F1 Score: 0.670312125255\n",
      "Confusion matrix:\n",
      "[[1005  515]\n",
      " [ 499 1034]]\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "confusion, scores = train.train_cv(classifier, X_train, Y_train)\n",
    "print \"Total tweets classified:\", X.shape[0]\n",
    "print \"F1 Score:\", sum(scores)/len(scores)\n",
    "print \"Confusion matrix:\"\n",
    "print confusion\n",
    "\n",
    "# Re-train with all data\n",
    "train.train(classifier, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on test data: 0.636612021858\n",
      "Confusion Matrix: \n",
      "[[265 131]\n",
      " [135 233]]\n",
      "precision 0.64010989011\n",
      "recall 0.633152173913\n",
      "accuracy 0.651832460733\n"
     ]
    }
   ],
   "source": [
    "# predict output on test set\n",
    "\n",
    "y_pred = train.predict(classifier, X_test, Y_test)\n",
    "print \"F1 score on test data:\", f1_score(Y_test, y_pred)\n",
    "print \"Confusion Matrix: \"\n",
    "print confusion_matrix(Y_test, y_pred)\n",
    "print 'precision', precision_score(Y_test, y_pred)\n",
    "print 'recall', recall_score(Y_test, y_pred)\n",
    "print 'accuracy', accuracy_score(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
